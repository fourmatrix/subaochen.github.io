{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(22)\n",
    "np.random.seed(22)\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "assert tf.__version__.startswith('2.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 加载数据，准备数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (25000, 80) tf.Tensor(1, shape=(), dtype=int64) tf.Tensor(0, shape=(), dtype=int32)\n",
      "x_test shape: (25000, 80)\n"
     ]
    }
   ],
   "source": [
    "batchsz = 128\n",
    "total_words = 10000\n",
    "max_review_len = 80\n",
    "# 也许会遇到打不开文件的错误，可以参考：\n",
    "# https://stackoverflow.com/questions/55890813/how-to-fix-object-arrays-cannot-be-loaded-when-allow-pickle-false-for-imdb-loa\n",
    "(x_train, y_train),(x_test, y_test) = keras.datasets.imdb.load_data(num_words = total_words)\n",
    "x_train = keras.preprocessing.sequence.pad_sequences(x_train, maxlen=max_review_len)\n",
    "x_test = keras.preprocessing.sequence.pad_sequences(x_test, maxlen=max_review_len)\n",
    "\n",
    "db_train = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "db_train = db_train.shuffle(10000).batch(batchsz, drop_remainder=True)\n",
    "db_test = tf.data.Dataset.from_tensor_slices((x_test, y_test))\n",
    "db_test = db_test.shuffle(10000).batch(batchsz, drop_remainder=True)\n",
    "\n",
    "print('x_train shape:', x_train.shape, tf.reduce_max(y_train), tf.reduce_min(x_train))\n",
    "print('x_test shape:', x_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 创建模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyRNN(keras.Model):\n",
    "    \n",
    "    def __init__(self, embedding_dim, units):\n",
    "        \"\"\"\n",
    "        embedding_dim:　嵌入层的神经元数量\n",
    "        units: RNN层的神经元数量\n",
    "        \"\"\"\n",
    "        super(MyRNN, self).__init__()\n",
    "        \n",
    "        # 输入-> Embedding，word2vec的过程\n",
    "        # [b,80] -> [b,80,100]\n",
    "        self.embedding = layers.Embedding(total_words, # 词汇表的尺寸\n",
    "                                          embedding_dim, # embedding层的神经元数量(维度)\n",
    "                                         input_length=max_review_len) # 每个输入的单词数量\n",
    "        \n",
    "        # Embedding -> RNN（可以有多层）\n",
    "        # [b,80,100] -> [b,64](units=64)\n",
    "        # 这里降维不会丢失信息，因为使用更多的神经元来表达\n",
    "        # 80维度的消失是因为在cell0中会逐个单词进行处理：处理过的维度自然就不需要了\n",
    "        self.rnn_cell0 = layers.SimpleRNNCell(units)\n",
    "        \n",
    "        # RNN -> Dense\n",
    "        # [b,64] -> [b,]\n",
    "        self.outlayer = layers.Dense(1, activation=\"sigmoid\")\n",
    "    \n",
    "    # 前向计算\n",
    "    def call(self, inputs, training=True):\n",
    "        \"\"\"\n",
    "        inputs: [b,80]\n",
    "        training: 鉴别处于训练状态还是预测状态\n",
    "        \"\"\"\n",
    "        \n",
    "        # 输入的word2vec\n",
    "        \n",
    "        # RNN的前向累积计算\n",
    "        \n",
    "        # 输出结果"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MyRNN(100,64)\n",
    "model.compile()\n",
    "model.fit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
